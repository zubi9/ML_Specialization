# Learnings


- Build ML models with NumPy & scikit-learn, build & train supervised models for prediction & binary classification tasks (linear, logistic regression)


- Build & train a neural network with TensorFlow to perform multi-class classification, & build & use decision trees & tree ensemble methods


- Apply best practices for ML development & use unsupervised learning techniques for unsupervised learning including clustering & anomaly detection


- Build recommender systems with a collaborative filtering approach & a content-based deep learning method & build a deep reinforcement learning model

An outline of the syllabus typically covered in Andrew Ng's Machine Learning course:

### Week 1: Introduction
- Introduction to Machine Learning
- Supervised Learning
- Unsupervised Learning

### Week 2: Linear Regression with One Variable
- Model Representation
- Cost Function
- Gradient Descent
- Debugging Gradient Descent

### Week 3: Linear Algebra Review
- Matrices and Vectors
- Addition and Scalar Multiplication
- Matrix Vector Multiplication
- Matrix Matrix Multiplication
- Matrix Multiplication Properties

### Week 4: Linear Regression with Multiple Variables
- Multiple Features
- Gradient Descent for Multiple Variables
- Feature Scaling
- Learning Rate

### Week 5: Logistic Regression
- Classification and Representation
- Hypothesis Representation
- Decision Boundary
- Cost Function
- Advanced Optimization
- Multiclass Classification
- Solving the Problem of Overfitting

### Week 6: Regularization
- The Problem of Overfitting
- Cost Function
- Regularized Linear Regression
- Regularized Logistic Regression
- Regularization and Bias/Variance
- Learning Curves

### Week 7: Neural Networks: Representation
- Motivation
- Neural Networks
- Model Representation
- Examples and Intuitions

### Week 8: Neural Networks: Learning
- Cost Function and Backpropagation
- Backpropagation in Practice
- Implementation Note: Unrolling Parameters
- Gradient Checking
- Random Initialization

### Week 9: Advice for Applying Machine Learning
- Evaluating a Learning Algorithm
- Bias vs. Variance
- Learning Curves
- Deciding What to Do Next Revisited

### Week 10: Machine Learning System Design
- Prioritizing What to Work On
- Error Analysis
- Error Metrics for Skewed Classes
- Trading Off Precision and Recall
- Data For Machine Learning

### Week 11: Support Vector Machines (SVMs)
- Large Margin Classification
- Kernels
- SVMs in Practice

### Week 12: Clustering
- Unsupervised Learning: Introduction
- K-Means Algorithm
- Optimization Objective
- Random Initialization
- Choosing the Number of Clusters
- Advice for Applying K-Means

### Week 13: Dimensionality Reduction
- Motivation
- Data Compression
- Principal Component Analysis (PCA)
- PCA Algorithm
- Applying PCA
- Reconstruction from Compressed Representation
- Choosing the Number of Principal Components

### Week 14: Anomaly Detection
- Density Estimation
- Gaussian Distribution
- Algorithm
- Developing and Evaluating an Anomaly Detection System
- Anomaly Detection vs. Supervised Learning
- Choosing What Features to Use

### Week 15: Recommender Systems
- Problem Formulation
- Collaborative Filtering
- Collaborative Filtering Algorithm
- Vectorization: Low Rank Matrix Factorization
- Implementational Detail: Mean Normalization

### Week 16: Large Scale Machine Learning
- Learning with Large Datasets
- Stochastic Gradient Descent
- Mini-Batch Gradient Descent
- Stochastic Gradient Descent Convergence
- Online Learning
- Map Reduce and Data Parallelism

### Week 17: Application Example: Photo OCR
- Problem Description and Pipeline
- Sliding Windows
- Getting Lots of Data and Artificial Data
- Ceiling Analysis: What Part of the Pipeline to Work on Next


# Machine Learning with Andrew Ng

Code is implemented in python of [Coursera's Machine Learning Course](https://www.coursera.org/specializations/machine-learning-introduction) (it uses Scikit-learn and NumPy). I also added some concepts and formulas that might be important to understand the algorithms.
